The cadofactor Python script is generally run with

./cadofactor.py parameterfile

All the parameters for the factorization are read from the parameter file,
but it is possible to specify such parameters on the command line, after
parameterfile.

For example, running

./cadofactor.py ../../params/params.c59 N=90377629292003121684002147101760858109247336549001090677693 tasks.workdir=/tmp/c59 tasks.execpath=$HOME/build/cado-nfs/normal server.whitelist=0.0.0.0/0

starts the cadofactor script, which also starts the server. It does not start any clients with this command line, so those would have to be started manually:

./wuclient2.py --server=https://quiche.loria.fr:8001 --certsha1=[Certificate SHA1]

where the --server and --certsha1 parameters should be given the URL and certificate SHA1 value of the server,
respectively, as printed by the cadofactor script. You can start an arbitrary number of client scripts, on any
machines that can connect to the server via HTTP.

If you want to let the server automatically start clients, you need to supply a list of hostnames on which to start clients, e.g.,

./cadofactor.py ../../params/params.c59 N=90377629292003121684002147101760858109247336549001090677693 tasks.workdir=/tmp/c59 tasks.execpath=$HOME/build/cado-nfs/normal slaves.hostnames=localhost slaves.nrclients=2 slaves.scriptpath=$HOME/git/cado-nfs/scripts/cadofactor

to let it start two clients on localhost. The scriptpath parameter must be the path to the directory on the client machine which contains wuclient2.py (and workunit.py).


For complex set-ups, it is preferable to write a parameter file. Some examples are in "parameters", "parameters.oar", and "parameters.rsa512.oar".
The params/params.c91 file contains extensive comments describing the most common parameters.

The .oar parameter files are meant for cadofactor scripts that run *inside* an OAR submission on clusters that use OAR as the job scheduler,
such as Grid5000, as they read the list of slave hostnames from the OAR node file.

For example,

oarsub -I
./cadofactor.py parameters.oar

factors the usual c59 test number using the nodes reserved via OAR, in this case one node.
The parameters.oar file contains the line
slaves.catrel.nrclients = 8
which tells the script to launch 8 clients on each unique host name (=node); the parameter
threads=2
causes all the programs to use two threads, resulting in 16 threads per node.

If a factorization is interrupted, it is usually possible to resume it where
it left off, simply by running cadofactor.py again with the same command
line parameters. These command line parameters are printed to the screen and
written to the .log file in the factorization's working directory on each
run.

If a factorization cannot be resumed for whatever reason, it is often
possible to salvage some of the output files which can then be imported into
a new factorization run of the same number, but with a new working
directory.


Importing a polynomial file
===========================

If you want to import a polynomial file (either an SNFS polynomial, or
if polynomial selection was already completed in an earlier run), use:

tasks.polyselect.import=xxx.poly

where xxx.poly is the name of the polynomial file (in CADO-NFS format).

This imports the polynomial and prevents any additional polynomial selection
from running, i.e., the imported polynomial is used unconditionally.


The polynomial selection run by cadofactor is performed in two phases:
the first phase searches for polynomials with good size property and keeps
in a priority queue the "nrkeep" most promising ones, then the second phase
root-optimizes these to find the overall best polynomial by Murphy E value.

You can import files that were previously produced by phase 1 (phase 2) into
phase 1 (phase 2) again; the imported files will be processed as if phase 1
(phase 2) had generated them by itself. Phase 1 will add any polynomials
from the imported files into its priority and forward the kept ones to
phase 2, while phase 2 chooses the best polynomial by Murphy E from the
imported ones and the ones it computes by itself.


If you want to import size-optimized polynomials into phase 1 of polynomial
selection and then continue polynomial search, use

tasks.polyselect.polyselect1.import_sopt=file
or
tasks.polyselect.polyselect1.import_sopt=@file

With @file, file should contain a list of files to import, one file name
per line. All polynomials from the given file(s) are imported and added to
the phase 1 priority queue, keeping the nrkeep best ones. Polynomial
selection phase 1 then continues normally. For example, if an earlier run
completed ad values up to ad=200000 and you want to resume the search from
there, you could use

tasks.polyselect.polyselect1.import_sopt=@list_of_existing_files tasks.polyselect.admin=200000

which imports the existing files, then resumes searching at ad=200000 up to
the admax value given in the parameter file.


If you want to import root-optimized polynomials into phase 2 of polynomial
selection and then continue polynomial seach, use

tasks.polyselect.polyselect2.import_ropt=file
or
tasks.polyselect.polyselect2.import_ropt=@file

This reads the polynomial(s) in the given file(s), then root-optimizes any
polynomials found in phase 1; the best polynomial (rated by the Murphy E
value) will be used for the sieving.

Warning: if a polynomial file does not specify a Murphy E value and is
imported into phase 2, its Murphy E value is set to 0 by default. Since any
polynomials found by the polynomial search have positive Murphy E, the
imported one will always "lose". To import, e.g., an SNFS polynomial
without Murphy E, use "tasks.polyselect.import", and not "import_ropt".


Importing relations
===================

If you want to import already computed relations, use:

tasks.sieve.import=foo

where "foo" is the name of the relation file to be imported (in CADO-NFS
format). Alternatively you can do:

tasks.sieve.import=@foo

where "foo" is a file containing several names of relation files, one file
name per line.

Adjust the tasks.sieve.sieving.qmin parameter accordingly to prevent
already-sieved special-q ranges from being sieved again.

File locking
============

The SqLite database used by cadofactor makes extensive use of file locking.
This requires that the underlying file system properly implements POSIX file
locking. One example of a file system that claims to, but does not, is
glusterfs, which leads to random SqLite errors. See the thread

http://gluster.org/pipermail/gluster-users/2011-September/031720.html

If you encounter "Database corrupted" or similar errors, try if storing the
working directory on a local (not network-mounted) file system resolves the
problem.

Controlling the excess
======================

By default CADO-NFS requires an excess (after the first singleton removal)
of 10% more relations than ideals. This is controlled by:

tasks.filter.purge.required_excess=0.1

If you want a larger excess, say 20%, just add on the cadofactor.py command
line (or in the parameter file):

tasks.filter.purge.required_excess=0.2

If any positive excess is enough:

tasks.filter.purge.required_excess=0.0

Note: if your factorization already started the linear algebra step, and you
want to do more sieving, you can restart it with a larger "rels_wanted" than
the current number of relations. For example if you have say 1000000 relations
(grep "is now" in the log file), just add in the cadofactor.py line:

tasks.sieve.rels_wanted=1000001

Printing the database
=====================

The wudb.py script can be used to print info on the workunits. For example,

./wudb.py -dbname /tmp/work/testrun.db -dump -assigned

prints all currently assigned work units.

