#ifndef LAS_MEMORY_HPP_
#define LAS_MEMORY_HPP_

#include <set>
#include <list>
#include <stack>
#include "macros.h"
#include "las-config.h"
#include "lock_guarded_container.hpp"

/* This structure is shared by threads that have the same memory binding.
 * It is in charge of providing momory-bound zones, e.g. for buckets, or
 * bucket regions.
 *
 * alloc()/free() calls are not meant to be fast, here.
 */

class las_memory_accessor {
    lock_guarded_container<std::stack<unsigned char*>> bucket_regions_pool;
    std::list<void*> large_pages_for_pool;

    /* large memory chunks follow the same logic as in utils/memory.c,
     * but we reimplement it here so as to stick to one memory binding
     * only.
     *
     * A large memory area may be returned as follows, in decreasing
     * priority order:
     *
     *  - if support is available, via mmap(...,MAP_HUGETLB). If it
     *  succeeds, we get a memory are in multiples of 2G, and call that
     *  an "mmapped region".
     *
     *  - if support is available, via malloc_aligned() +
     *  madvise(MADV_HUGEPAGE). If it succeeds, we call that a "malloced
     *  region"
     *
     *  - otherwise, via malloc_aligned(), and it is still called a
     *  "default malloced region".
     *
     * How the requested size is rounded up depends on the mode.
     */
    lock_guarded_container<std::set<void*>> was_mmapped; // used on free()

    void touch(void *, size_t);
    public:

    static inline size_t bucket_region_size() {
        /* round to next multiple of 128 */
        return (((BUCKET_REGION + MEMSET_MIN) - 1) | 127) + 1;
    }
    unsigned char * alloc_bucket_region();
    void free_bucket_region(unsigned char *);

    void * physical_alloc(size_t, bool = false) ATTR_ASSUME_ALIGNED(256);
    void physical_free(void*, size_t);

    las_memory_accessor() = default;
    las_memory_accessor(las_memory_accessor const &) = delete;
    las_memory_accessor(las_memory_accessor&&) = default;
    ~las_memory_accessor();
};

#endif	/* LAS_MEMORY_HPP_ */
